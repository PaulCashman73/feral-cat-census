{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook assumes we have a folder of segmented images of cats.  See the notebook notebooks/yolo/extract_from_yolo_instance_segmentation_model.ipynb to see how to produce such a folder.\n",
    "\n",
    "Given the folkder of segmented images, this notebook maps the segmented images to a dense vector representation, and uses cosine similarity to tell how close two images are to one another.  This is implemented in the SentenceTransformer module.  The arbitrary parameter is the threshold above which two images will be clustered together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image display\n",
    "import IPython.display as display\n",
    "from PIL import Image\n",
    "\n",
    "# for everything else\n",
    "from google.colab import drive\n",
    "import glob\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.image import imread\n",
    "import pandas as pd\n",
    "import cv2\n",
    "\n",
    "%pip install ultralytics\n",
    "from ultralytics import YOLO\n",
    "\n",
    "%pip install sentence_transformers\n",
    "from sentence_transformers import SentenceTransformer, util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get access to Google Drive\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths to instance segmentation model and the folder where the segmented images will be stored\n",
    "path_to_instance_segmentation_model = '/content/gdrive/MyDrive/Cat images/models/feral-cat-segmentation.v1i.yolov8/200-epochs-/weights/best.pt'\n",
    "path_to_segmented_images = '/content/unusable-selections-segmented'\n",
    "segmented_image_wildcard_filetype = '*.png' # File type, expressed as wildcard, of segmented images in above folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the OpenAI CLIP Model\n",
    "print('Loading CLIP Model...')\n",
    "model = SentenceTransformer('clip-ViT-B-32')\n",
    "\n",
    "# Next we compute the embeddings\n",
    "image_names = sorted(list(glob.glob(os.path.join(path_to_segmented_images, segmented_image_wildcard_filetype))))\n",
    "unclustered_image_names = image_names.copy() # used to track which images have been not yet been added to a cluster\n",
    "print(\"Number of images: {}\".format(len(image_names)))\n",
    "encoded_image = model.encode([Image.open(os.path.join(path_to_segmented_images, filepath)) for filepath in image_names], batch_size=128, convert_to_tensor=True, show_progress_bar=True)\n",
    "\n",
    "# Now we run the clustering algorithm. This function compares images against\n",
    "# all other images and returns a list with the pairs that have the highest\n",
    "# cosine similarity score\n",
    "processed_images = util.paraphrase_mining_embeddings(encoded_image)\n",
    "\n",
    "# =================\n",
    "# DUPLICATES\n",
    "# =================\n",
    "print('Finding duplicate images...')\n",
    "# Filter list for duplicates. Results are triplets (score, image_id1, image_id2) and is scorted in decreasing order\n",
    "# A duplicate image will have a score of 1.00\n",
    "# It may be 0.9999 due to lossy image compression (.jpg)\n",
    "duplicates = [image for image in processed_images if image[0] >= 0.999]\n",
    "\n",
    "def show_dups(id1, id2):\n",
    "  fig = plt.figure(figsize=(10,8))\n",
    "  ax = fig.add_subplot(1, 2, 1)\n",
    "  ax.imshow(imread(image_names[id1]))\n",
    "  ax = fig.add_subplot(1, 2, 2)\n",
    "  ax.imshow(imread(image_names[id2]))\n",
    "  plt.axis('off')\n",
    "  plt.title('Duplicates')\n",
    "  plt.show()\n",
    "\n",
    "def show_cluster(cluster, high_or_low):\n",
    "  fig = plt.figure(figsize=(10,8))\n",
    "  for i, image_name in enumerate(cluster[1:]): # skip the first element (the score)\n",
    "    ax = fig.add_subplot(1, len(cluster) - 1, i+1)\n",
    "    ax.imshow(imread(image_name))\n",
    "    plt.axis('off')\n",
    "  avg_similarity = str(round(cluster[0] / (len(cluster) - 2), 3))\n",
    "  if high_or_low == 'high':\n",
    "    plt.title('High Similarity Cluster (avg similarity: ' + avg_similarity + ')')\n",
    "  elif high_or_low == 'low':\n",
    "    plt.title('Low Similarity Cluster (avg similarity: ' + avg_similarity +')')\n",
    "  else:\n",
    "    plt.title('Cluster')\n",
    "  plt.show()\n",
    "\n",
    "# Output the top X duplicate images\n",
    "for score, image_id1, image_id2 in duplicates:\n",
    "    print(\"\\nScore: {:.3f}%\".format(score * 100))\n",
    "    print(image_names[image_id1])\n",
    "    print(image_names[image_id2])\n",
    "    show_dups(image_id1, image_id2)\n",
    "\n",
    "# =================\n",
    "# NEAR DUPLICATES\n",
    "# =================\n",
    "print('Finding near duplicate images...')\n",
    "# Use a threshold parameter to identify two images as similar. By setting the threshold lower,\n",
    "# you will get larger clusters which have less similar images in it. Threshold 0 - 1.00\n",
    "# A threshold of 1.00 means the two images are exactly the same. Since we are finding near\n",
    "# duplicate images, we can set it at 0.99 or any number 0 < X < 1.00.\n",
    "threshold = 0.99\n",
    "near_duplicates = sorted([image for image in processed_images if image[0] < threshold], key=lambda x: x[0], reverse=True)\n",
    "print('Number of near-duplicates: {}'.format(len(near_duplicates)))\n",
    "scores_only = [image[0] for image in processed_images if image[0] < threshold]\n",
    "print('Max score: {}, min score: {}'.format(max(scores_only), min(scores_only)))\n",
    "\n",
    "# ===============\n",
    "# Assemble clusters based on similarity scores\n",
    "#\n",
    "# Given a CLUSTER_THRESHOLD value, find all pairs of images whose similarity score is\n",
    "# >= the CLUSTER_THRESHOLD.  For each image in the pair, find an array within the\n",
    "# clusters array containing that image's path.  If one is found, add the other image's\n",
    "# pathname to the cluster; otherwise, start a new cluster with the paths of both\n",
    "# images.  When a path is added to a cluster, remove that path from the list of all\n",
    "# image paths.  When all image pairs exceeding the threshold have been processed, proceed as follows\n",
    "# until all paths have been removed from the list of all image paths:\n",
    "#\n",
    "# Continue processing pairs as above, adding new clusters and removing paths from the\n",
    "# list of all paths, but with these changes:\n",
    "#.    (1) Do not add any path to the clusters created from pairs exceeding the threshold\n",
    "#.    (2) Do not add to a cluster any path that appears in one of the clusters whose\n",
    "#         members exceed the threshold.  This may well lead to singleton clusters, and that's OK.\n",
    "# ===============\n",
    "\n",
    "HIGH_CLUSTER_THRESHOLD = 0.92\n",
    "LOW_CLUSTER_THRESHOLD = 0.85\n",
    "high_threshold_clusters = []\n",
    "low_threshold_clusters = []\n",
    "\n",
    "def normalize_scores(scores, processed_images):\n",
    "    # Normalize the scores\n",
    "    max_score = max(scores)\n",
    "    min_score = min(scores)\n",
    "    normalized_scores = []\n",
    "    for image in processed_images:\n",
    "        score = image[0]\n",
    "        if score == max_score:\n",
    "            image[0] = 1\n",
    "        elif score == min_score:\n",
    "            image[0] = 0\n",
    "        else:\n",
    "            image[0] = (score - min_score) / (max_score - min_score)\n",
    "\n",
    "def is_high_threshold_cluster(row):\n",
    "    if row[0] >= HIGH_CLUSTER_THRESHOLD:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def is_low_threshold_cluster(row):\n",
    "    if row[0] < HIGH_CLUSTER_THRESHOLD and row[0] >= LOW_CLUSTER_THRESHOLD:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def get_cluster_image_names(row):\n",
    "    return [image_names[row[1]], image_names[row[2]]]\n",
    "\n",
    "def is_one_cat_in_high_threshold_cluster(row):\n",
    "  file1, file2 = get_cluster_image_names(row)\n",
    "  for cluster in high_threshold_clusters:\n",
    "    if file1 in cluster or file2 in cluster:\n",
    "      return True\n",
    "  return False\n",
    "\n",
    "def remove_from_unclustered_images(files):\n",
    "    for file in files:\n",
    "        if file in unclustered_image_names:\n",
    "            unclustered_image_names.remove(file)\n",
    "\n",
    "def add_to_cluster(row, clusters):\n",
    "    file1, file2 = get_cluster_image_names(row)\n",
    "    for cluster in clusters:\n",
    "        if file1 in cluster:\n",
    "            if file2 not in cluster:\n",
    "                cluster[0] += row[0]\n",
    "                cluster.append(file2)\n",
    "            return\n",
    "        elif file2 in cluster:\n",
    "            if file1 not in cluster:\n",
    "                cluster[0] += row[0]\n",
    "                cluster.append(file1)\n",
    "            return\n",
    "    # Didn't find file1 or file2 in any cluster, so add a new one\n",
    "    # First element of every cluster is the total of similarity scores\n",
    "    # for all pairs added to the cluster\n",
    "    clusters.append([row[0], file1, file2])\n",
    "\n",
    "\n",
    "print('Normalizing scores...')\n",
    "# Normalize the scores\n",
    "normalize_scores(scores_only, near_duplicates)\n",
    "print('Clustering images based on normalized similarity scores...')\n",
    "# Process every pair regardless of similarity score\n",
    "for row in near_duplicates:\n",
    "    # Continue processing until every image has been assigned to a cluster\n",
    "    if len(unclustered_image_names) > 0:\n",
    "        # If similarity score beats threshold, add row to a cluster in\n",
    "        # the high threshold cluster list, or add a new cluster there\n",
    "        if is_high_threshold_cluster(row):\n",
    "          add_to_cluster(row, high_threshold_clusters)\n",
    "        # If similarity score is below the high threshold, but above the low threshold,\n",
    "        # eadd row to a low threshold cluster, but only if neither image has already\n",
    "        # been assigned to a high threshold cluster\n",
    "        elif not is_one_cat_in_high_threshold_cluster(row) and is_low_threshold_cluster(row):\n",
    "          add_to_cluster(row, low_threshold_clusters)\n",
    "        # Remove file names from list of unclustered images\n",
    "        file1, file2 = get_cluster_image_names(row)\n",
    "        remove_from_unclustered_images([file1, file2])\n",
    "    else:\n",
    "        break\n",
    "\n",
    "print('Number of high threshold clusters: {}'.format(len(high_threshold_clusters)))\n",
    "print('Number of low threshold clusters: {}'.format(len(low_threshold_clusters)))\n",
    "\n",
    "for cluster in sorted(high_threshold_clusters, key = lambda cluster: cluster[0] / (len(cluster) - 2), reverse=True):\n",
    "  show_cluster(cluster, 'high')\n",
    "for cluster in sorted(low_threshold_clusters, key = lambda cluster: cluster[0] / (len(cluster) - 2), reverse=True):\n",
    "  show_cluster(cluster, 'low')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
