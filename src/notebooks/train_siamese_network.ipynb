{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyM78aBtVFIgYU0On2Qyc4jm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pcashman21/feral-cat-census/blob/main/src/notebooks/train_siamese_network.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This notebook trains a siamese neural network to recognize whether two cat faces are the same cat.  For line-by-line details of the code, see https://pyimagesearch.com/2020/11/30/siamese-networks-with-keras-tensorflow-and-deep-learning/.\n",
        "\n",
        "The training data is generated by the script `image_pair_generator.ipynb`."
      ],
      "metadata": {
        "id": "EaIhsArbb3QI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The next cell is the `config.py` file."
      ],
      "metadata": {
        "id": "lt-CQNMQfVYV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Configuration parameters\n",
        "\n",
        "# import the necessary packages\n",
        "import os\n",
        "\n",
        "# specify the shape of the inputs for our network\n",
        "IMG_SIZE = 244 # Must agree with this variable in the image_pair_generator notebook\n",
        "IMG_SHAPE = (IMG_SIZE, IMG_SIZE, 3) # 3 channels for RGB\n",
        "EMBEDDING_DIMENSIONS = 48 # number of dimensions of embedding vector\n",
        "\n",
        "# specify the batch size and number of epochs\n",
        "BATCH_SIZE = 64\n",
        "EPOCHS = 100\n",
        "\n",
        "# define the path to the base output directory\n",
        "BASE_OUTPUT = \"output\"\n",
        "# define the path to the training images folder\n",
        "IMAGE_FOLDER = 'cat-face-transformed'\n",
        "\n",
        "# use the base output path to derive the path to the serialized\n",
        "# model along with training history plot\n",
        "MODEL_PATH = os.path.sep.join([BASE_OUTPUT, \"siamese_model\"])\n",
        "PLOT_PATH = os.path.sep.join([BASE_OUTPUT, \"plot.png\"])"
      ],
      "metadata": {
        "id": "kUi9eyBtcQ7L"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The next two cells comprise the `siamese_network.py` file."
      ],
      "metadata": {
        "id": "wCl5Svozfh0K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import the necessary packages\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Conv2D, Dense, Dropout, GlobalAveragePooling2D, MaxPooling2D, Lambda"
      ],
      "metadata": {
        "id": "pyJ--TAVdQ2f"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_siamese_model(inputShape=IMG_SHAPE, embeddingDim=EMBEDDING_DIMENSIONS):\n",
        "  \"\"\"\n",
        "  Build a siamese neural network\n",
        "\n",
        "  # Arguments\n",
        "  inputShape:   shape of the input images\n",
        "  embeddingDim: dimension of the embedding vector\n",
        "\n",
        "  # Returns\n",
        "  a Keras model instance\n",
        "  \"\"\"\n",
        "\n",
        "\t# specify the inputs for the feature extractor network\n",
        "  inputs = Input(inputShape)\n",
        "\n",
        "\t# define the first set of CONV => RELU => POOL => DROPOUT layers\n",
        "  x = Conv2D(64, (2, 2), padding=\"same\", activation=\"relu\")(inputs)\n",
        "  x = MaxPooling2D(pool_size=(2, 2))(x)\n",
        "  x = Dropout(0.3)(x)\n",
        "\n",
        "\t# second set of CONV => RELU => POOL => DROPOUT layers\n",
        "  x = Conv2D(64, (2, 2), padding=\"same\", activation=\"relu\")(x)\n",
        "  x = MaxPooling2D(pool_size=2)(x)\n",
        "  x = Dropout(0.3)(x)\n",
        "\n",
        "  # prepare the final outputs\n",
        "  pooledOutput = GlobalAveragePooling2D()(x)\n",
        "  outputs = Dense(embeddingDim)(pooledOutput)\n",
        "\n",
        "  # build the model and return it\n",
        "  model = Model(inputs, outputs)\n",
        "  return model"
      ],
      "metadata": {
        "id": "Nau0ik98dsRs"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The next six cells comprise the `utils.py` file."
      ],
      "metadata": {
        "id": "rvcZVsqUf0WV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import the necessary packages\n",
        "import tensorflow.keras.backend as K\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "Oeu61X-1fs-S"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def read_image(filename):\n",
        "  return plt.imread(os.path.join('/content', IMAGE_FOLDER, filename))"
      ],
      "metadata": {
        "id": "xDX7B0GWjxA-"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_train_test_split(df):\n",
        "  \"\"\"\n",
        "  Splits the data into training and testing sets.\n",
        "\n",
        "  df is assumed to have the following structure:\n",
        "  1. df.columns = [filename, label]\n",
        "  2. Each filename of an original (not transformed) image is of the form 'imgNNN.jpg'\n",
        "  3. df.label is a string which is the numeric part of the filename (as a string, not as an int)\n",
        "  4. There are M transforms of each original.\n",
        "  \"\"\"\n",
        "  # split the data into training and testing splits using 75% of\n",
        "\t# the data for training and the remaining 25% for testing\n",
        "  labels = df['label'].unique()\n",
        "  train_df = pd.DataFrame(columns=df.columns)\n",
        "  test_df = pd.DataFrame(columns=df.columns)\n",
        "  for i in range(len(labels)):\n",
        "    label = labels[i]\n",
        "    label_index = df.groupby('label').get_group(label).index.to_list()\n",
        "    train_index = label_index[:int(len(label_index) * 0.75)]\n",
        "    test_index = label_index[int(len(label_index) * 0.75):]\n",
        "    train_df = pd.concat([train_df, df.iloc[train_index]])\n",
        "    test_df = pd.concat([test_df, df.iloc[test_index]])\n",
        "  return [train_df['filename'], train_df['label']], [test_df['filename'], test_df['label']]"
      ],
      "metadata": {
        "id": "XV6NKKWZiWYX"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def make_pairs(images, labels):\n",
        "\t\"\"\"\n",
        "\tMake a train or test set for the siamese neural network by creating\n",
        "\ta set of image pairs and a corresponding set of labels which are\n",
        "\teither positive or negative.\n",
        "\n",
        "\t# Arguments\n",
        "\t\timages: list of images\n",
        "\t\tlabels: list of labels\n",
        "\t# Returns\n",
        "\t\ttuple of (image pairs, pos/neg labels)\n",
        "\t\"\"\"\n",
        "\t# initialize two empty lists to hold the (image, image) pairs and\n",
        "\t# labels to indicate if a pair is positive or negative\n",
        "\tpairImages = []\n",
        "\tpairLabels = []\n",
        "\n",
        "  # Build a list of indexes for each class label that\n",
        "\t# provides the indexes for all examples with a given label\n",
        "\tidx = [np.where(labels == i)[0] for i in np.unique(labels)]\n",
        "\t# Create a dataframe whose index is the set of unique labels\n",
        "\t# and whose columns are the index values of images which belong\n",
        "\t# to that label.\n",
        "\tidx_df = pd.DataFrame(idx, index=np.unique(labels))\n",
        "\n",
        "  # loop over all images\n",
        "\tfor idxA in range(len(images)):\n",
        "\t\t# grab the current image and label belonging to the current\n",
        "\t\t# iteration\n",
        "\t\tcurrentImage = images.iloc[idxA]\n",
        "\t\tlabel = labels.iloc[idxA]\n",
        "\t\t# randomly pick an image that belongs to the *same* class\n",
        "\t\t# label\n",
        "\t\tindexes = idx_df.loc[label].values\n",
        "\t\tidxB = np.random.choice(indexes)\n",
        "\t\tposImage = images.iloc[idxB]\n",
        "\t\t# prepare a positive pair and update the images and labels\n",
        "\t\t# lists, respectively\n",
        "\t\tpairImages.append([currentImage, posImage])\n",
        "\t\tpairLabels.append([1])\n",
        "    # grab the indices for each of the class labels *not* equal to\n",
        "\t\t# the current label and randomly pick an image corresponding\n",
        "\t\t# to a label *not* equal to the current label\n",
        "\t\tnegIdx = np.where(np.unique(labels) != label)[0]\n",
        "\t\tnegImage = images.iloc[np.random.choice(negIdx)]\n",
        "\t\t# prepare a negative pair of images and update our lists\n",
        "\t\tpairImages.append([currentImage, negImage])\n",
        "\t\tpairLabels.append([0])\n",
        "\t# return a 2-tuple of our image pairs and labels\n",
        "\treturn (np.array(pairImages), np.array(pairLabels))"
      ],
      "metadata": {
        "id": "HuHgq6lpf8zP"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def euclidean_distance(vectors):\n",
        "  \"\"\"\n",
        "  Compute the euclidean distance between two feature vectors.\n",
        "\n",
        "  # Arguments\n",
        "  vectors:  list containing two feature vectors\n",
        "\n",
        "  # Returns\n",
        "  euclidean distance between the vectors\n",
        "  \"\"\"\n",
        "\t# unpack the vectors into separate lists\n",
        "  (featsA, featsB) = vectors\n",
        "\t# compute the sum of squared distances between the vectors\n",
        "  sumSquared = K.sum(K.square(featsA - featsB), axis=1,\n",
        "\t\tkeepdims=True)\n",
        "\t# return the euclidean distance between the vectors\n",
        "  return K.sqrt(K.maximum(sumSquared, K.epsilon()))"
      ],
      "metadata": {
        "id": "VN-qBDzbgMUS"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_training(H, plotPath):\n",
        "  \"\"\"\n",
        "  Plot the training history for loss and accuracy\n",
        "\n",
        "\n",
        "  # Arguments\n",
        "  H: training history\n",
        "  plotPath: path to save the plot\n",
        "  \"\"\"\n",
        "\n",
        "\t# construct a plot that plots and saves the training history\n",
        "  plt.style.use(\"ggplot\")\n",
        "  plt.figure()\n",
        "  plt.plot(H.history[\"loss\"], label=\"train_loss\")\n",
        "  plt.plot(H.history[\"val_loss\"], label=\"val_loss\")\n",
        "  plt.plot(H.history[\"accuracy\"], label=\"train_acc\")\n",
        "  plt.plot(H.history[\"val_accuracy\"], label=\"val_acc\")\n",
        "  plt.title(\"Training Loss and Accuracy\")\n",
        "  plt.xlabel(\"Epoch #\")\n",
        "  plt.ylabel(\"Loss/Accuracy\")\n",
        "  plt.legend(loc=\"lower left\")\n",
        "  plt.savefig(plotPath)"
      ],
      "metadata": {
        "id": "Ou26dF2Lg6M-"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The next two cells comprise the file `train_siamese_network.py`."
      ],
      "metadata": {
        "id": "D8NFkiM7htYt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# BE SURE to upload `cat-face-transformed.zip` before running this cell.\n",
        "!unzip cat-face-transformed.zip\n",
        "# Print the number of unzipped files\n",
        "!ls -1 ./cat-face-transformed | wc -l"
      ],
      "metadata": {
        "id": "suE4m_Hsit6a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# BE SURE to upload file `cat-face-transformed.csv` before running this cell\n",
        "df = pd.read_csv(os.path.join('/content', IMAGE_FOLDER + '.csv'))"
      ],
      "metadata": {
        "id": "ew5mV_KqjKVE"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load cat-face-transformed dataset, consisting of 244x244 images of cats.\n",
        "# The dataset has about 100 original images of cats amd 50 transforms of\n",
        "# each original.\n",
        "print(\"[INFO] loading cat-face-transformed dataset...\")\n",
        "(trainX, trainY), (testX, testY) = load_train_test_split(df)\n",
        "\n",
        "# add a channel dimension to the images\n",
        "trainX = np.expand_dims(trainX, axis=-1)\n",
        "testX = np.expand_dims(testX, axis=-1)\n",
        "\n",
        "# prepare the positive and negative pairs\n",
        "print(\"[INFO] preparing positive and negative pairs...\")\n",
        "(pairTrain, labelTrain) = make_pairs(trainX, trainY)\n",
        "(pairTest, labelTest) = make_pairs(testX, testY)\n",
        "\n",
        "# configure the siamese network\n",
        "print(\"[INFO] building siamese network...\")\n",
        "imgA = Input(shape=IMG_SHAPE)\n",
        "imgB = Input(shape=IMG_SHAPE)\n",
        "featureExtractor = build_siamese_model(IMG_SHAPE)\n",
        "featsA = featureExtractor(imgA)\n",
        "featsB = featureExtractor(imgB)\n",
        "\n",
        "# finally, construct the siamese network\n",
        "distance = Lambda(euclidean_distance)([featsA, featsB])\n",
        "outputs = Dense(1, activation=\"sigmoid\")(distance)\n",
        "model = Model(inputs=[imgA, imgB], outputs=outputs)\n",
        "\n",
        "# compile the model\n",
        "print(\"[INFO] compiling model...\")\n",
        "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\",\n",
        "\tmetrics=[\"accuracy\"])\n",
        "\n",
        "# train the model\n",
        "print(\"[INFO] training model...\")\n",
        "history = model.fit(\n",
        "\t[pairTrain[:, 0], pairTrain[:, 1]], labelTrain[:],\n",
        "\tvalidation_data=([pairTest[:, 0], pairTest[:, 1]], labelTest[:]),\n",
        "\tbatch_size=BATCH_SIZE,\n",
        "\tepochs=EPOCHS)\n",
        "\n",
        "# serialize the model to disk\n",
        "print(\"[INFO] saving siamese model...\")\n",
        "model.save(MODEL_PATH)\n",
        "\n",
        "# plot the training history\n",
        "print(\"[INFO] plotting training history...\")\n",
        "plot_training(history, PLOT_PATH)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "id": "6GPfDuhkh616",
        "outputId": "8ecb63a0-1285-4fac-8dea-1f4dc1766bed"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] loading cat-face-transformed dataset...\n",
            "[INFO] preparing positive and negative pairs...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-f2229a484fc3>\u001b[0m in \u001b[0;36m<cell line: 13>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# prepare the positive and negative pairs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"[INFO] preparing positive and negative pairs...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0;34m(\u001b[0m\u001b[0mpairTrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabelTrain\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_pairs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpairTest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabelTest\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_pairs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtestY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-b3eef24f1d0c>\u001b[0m in \u001b[0;36mmake_pairs\u001b[0;34m(images, labels)\u001b[0m\n\u001b[1;32m     28\u001b[0m                 \u001b[0;31m# grab the current image and label belonging to the current\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m                 \u001b[0;31m# iteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m                 \u001b[0mcurrentImage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midxA\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m                 \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midxA\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m                 \u001b[0;31m# randomly pick an image that belongs to the *same* class\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'iloc'"
          ]
        }
      ]
    }
  ]
}