{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNtyYA2AtGHQ9Qkm9eJAPrd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pcashman21/feral-cat-census/blob/main/src/notebooks/cluster_yolo_images.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KgHt-5NddH4r",
        "outputId": "3e6acd5e-7f74-4a81-8bfb-def0d9dad157"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ultralytics\n",
            "  Downloading ultralytics-8.0.195-py3-none-any.whl (618 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/618.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.0/618.9 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━\u001b[0m \u001b[32m481.3/618.9 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m618.9/618.9 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (3.7.1)\n",
            "Requirement already satisfied: numpy>=1.22.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.23.5)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.8.0.76)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.4.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (6.0.1)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.31.0)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.11.3)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.0.1+cu118)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.15.2+cu118)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.66.1)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.5.3)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.12.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.0.0)\n",
            "Collecting thop>=0.1.1 (from ultralytics)\n",
            "  Downloading thop-0.1.1.post2209072238-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.1.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.43.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (23.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2023.3.post1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2.0.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2023.7.22)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.12.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.8.0->ultralytics) (3.27.6)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.8.0->ultralytics) (17.0.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Installing collected packages: thop, ultralytics\n",
            "Successfully installed thop-0.1.1.post2209072238 ultralytics-8.0.195\n"
          ]
        }
      ],
      "source": [
        "# for loading/processing the images\n",
        "from keras.preprocessing.image import load_img\n",
        "from keras.preprocessing.image import img_to_array\n",
        "from keras.applications.vgg16 import preprocess_input\n",
        "\n",
        "# models\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from keras.models import Model, load_model\n",
        "\n",
        "# clustering and dimension reduction\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "# for everything else\n",
        "from google.colab import drive\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import cv2\n",
        "\n",
        "!pip install ultralytics\n",
        "from ultralytics import YOLO"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Rks5VB0SkSj",
        "outputId": "66291ccf-0496-4e0c-b9dc-f41db5260126"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path_to_best_cat_detector = '/content/gdrive/My Drive/Cat images/feral-cat-census.v1i.yolov8/runs/detect/train/weights/best.pt'\n",
        "path_to_images = '/content/gdrive/My Drive/Cat images/original_images/'\n",
        "path_to_cropped_images = '/content/runs/detect/cropped_images_2'"
      ],
      "metadata": {
        "id": "8JRu8gi8eXfZ"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cat_detector_model = YOLO(path_to_best_cat_detector)  # load the cat detector model"
      ],
      "metadata": {
        "id": "-c1VGJAWewO2"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the YOLOv8 model and get a YOLO Results object\n",
        "# https://docs.ultralytics.com/modes/predict/#working-with-results\n",
        "# results = cat_detector_model.predict(source=path_to_image)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "091mCNuadyL1",
        "outputId": "4a687985-12ea-4ee4-c262-b6d3ea8b077b"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "image 1/1 /content/gdrive/My Drive/Cat images/original_images/nreading/IMG_0507.jpeg: 480x640 1 cat, 22.6ms\n",
            "Speed: 8.9ms preprocess, 22.6ms inference, 9.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Results saved to \u001b[1mruns/detect/predict2\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract the image sub areas and save them\n",
        "# for r in results:\n",
        "#  r.save_crop(save_dir='./runs/detect/cropped_images')\n"
      ],
      "metadata": {
        "id": "AxqjBt9lZR8x"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Parameters for featire clustering model\n",
        "INPUT_SHAPE = (224,224, 3) ## Pixel size of images accepted by VGG, in each of 3 channels\n",
        "IMG_SIZE = INPUT_SHAPE[:2]"
      ],
      "metadata": {
        "id": "SmkABHS1zaOd"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load VGG model for image clustering\n",
        "image_cluster_model = VGG16()\n",
        "# remove the output layer\n",
        "image_cluster_model = Model(inputs=image_cluster_model.inputs, outputs=image_cluster_model.layers[-2].output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qKffLI0CznIQ",
        "outputId": "e7098235-9244-49cb-9acf-0a3a57dd8707"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels.h5\n",
            "553467096/553467096 [==============================] - 5s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_features(file, model, img_size=IMG_SIZE):\n",
        "    # load the image as a 224x224 array\n",
        "    img = load_img(file, target_size=img_size)\n",
        "    # convert from 'PIL.Image.Image' to numpy array\n",
        "    img = np.array(img)\n",
        "    # reshape the data for the model reshape(num_of_samples, dim 1, dim 2, channels)\n",
        "    reshaped_img = np.expand_dims(img, axis=0)\n",
        "    # prepare image for model\n",
        "    imgx = preprocess_input(reshaped_img)\n",
        "    # get the feature vector\n",
        "    features = model.predict(imgx, use_multiprocessing=True)\n",
        "    return features"
      ],
      "metadata": {
        "id": "hRn6a7H8z0X1"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from https://github.com/arvkevi/kneed/blob/main/kneed/knee_locator.py\n",
        "# Implementation of Kneedle algorithm at repo https://github.com/arvkevi/kneed\n",
        "import numpy as np\n",
        "from scipy import interpolate\n",
        "from scipy.signal import argrelextrema\n",
        "from typing import Tuple, Optional, Iterable\n",
        "\n",
        "VALID_CURVE = [\"convex\", \"concave\"]\n",
        "VALID_DIRECTION = [\"increasing\", \"decreasing\"]\n",
        "\n",
        "try:\n",
        "    import matplotlib.pyplot as plt\n",
        "except ImportError:\n",
        "    _has_matplotlib = False\n",
        "    _matplotlib_not_found_err = ModuleNotFoundError(\n",
        "        \"This function needs Matplotlib to be executed. Please run command `pip install kneed[plot]` \"\n",
        "    )\n",
        "else:\n",
        "    _has_matplotlib = True\n",
        "\n",
        "\n",
        "class KneeLocator(object):\n",
        "    \"\"\"\n",
        "    Once instantiated, this class attempts to find the point of maximum\n",
        "    curvature on a line. The knee is accessible via the `.knee` attribute.\n",
        "\n",
        "    :param x: x values, must be the same length as y.\n",
        "    :type x: 1D array of shape (`number_of_y_values`,) or list\n",
        "    :param y: y values, must be the same length as x.\n",
        "    :type y: 1D array of shape (`number_of_y_values`,) or list\n",
        "    :param S: Sensitivity, the number of minimum number of data points below the local distance maximum before calling a knee. The original paper suggests default of 1.0\n",
        "    :type S: float\n",
        "    :param curve: If 'concave', algorithm will detect knees. If 'convex', it\n",
        "        will detect elbows.\n",
        "    :type curve: str\n",
        "    :param direction: one of {\"increasing\", \"decreasing\"}\n",
        "    :type direction: str\n",
        "    :param interp_method: one of {\"interp1d\", \"polynomial\"}\n",
        "    :type interp_method: str\n",
        "    :param online: kneed will correct old knee points if True, will return first knee if False\n",
        "    :type online: bool\n",
        "    :param polynomial_degree: The degree of the fitting polynomial. Only used when interp_method=\"polynomial\". This argument is passed to numpy polyfit `deg` parameter.\n",
        "    :type polynomial_degree: int\n",
        "    :ivar x: x values.\n",
        "    :vartype x: array-like\n",
        "    :ivar y: y values.\n",
        "    :vartype y: array-like\n",
        "    :ivar S: Sensitivity, original paper suggests default of 1.0\n",
        "    :vartype S: integer\n",
        "    :ivar curve: If 'concave', algorithm will detect knees. If 'convex', it\n",
        "        will detect elbows.\n",
        "    :vartype curve: str\n",
        "    :ivar direction: one of {\"increasing\", \"decreasing\"}\n",
        "    :vartype direction: str\n",
        "    :ivar interp_method: one of {\"interp1d\", \"polynomial\"}\n",
        "    :vartype interp_method: str\n",
        "    :ivar online: kneed will correct old knee points if True, will return first knee if False\n",
        "    :vartype online: str\n",
        "    :ivar polynomial_degree: The degree of the fitting polynomial. Only used when interp_method=\"polynomial\". This argument is passed to numpy polyfit `deg` parameter.\n",
        "    :vartype polynomial_degree: int\n",
        "    :ivar N: The number of `x` values in the\n",
        "    :vartype N: integer\n",
        "    :ivar all_knees: A set containing all the x values of the identified knee points.\n",
        "    :vartype all_knees: set\n",
        "    :ivar all_norm_knees: A set containing all the normalized x values of the identified knee points.\n",
        "    :vartype all_norm_knees: set\n",
        "    :ivar all_knees_y: A list containing all the y values of the identified knee points.\n",
        "    :vartype all_knees_y: list\n",
        "    :ivar all_norm_knees_y: A list containing all the normalized y values of the identified knee points.\n",
        "    :vartype all_norm_knees_y: list\n",
        "    :ivar Ds_y: The y values from the fitted spline.\n",
        "    :vartype Ds_y: numpy array\n",
        "    :ivar x_normalized: The normalized x values.\n",
        "    :vartype x_normalized: numpy array\n",
        "    :ivar y_normalized: The normalized y values.\n",
        "    :vartype y_normalized: numpy array\n",
        "    :ivar x_difference: The x values of the difference curve.\n",
        "    :vartype x_difference: numpy array\n",
        "    :ivar y_difference: The y values of the difference curve.\n",
        "    :vartype y_difference: numpy array\n",
        "    :ivar maxima_indices: The indices of each of the maxima on the difference curve.\n",
        "    :vartype maxima_indices: numpy array\n",
        "    :ivar maxima_indices: The indices of each of the maxima on the difference curve.\n",
        "    :vartype maxima_indices: numpy array\n",
        "    :ivar x_difference_maxima: The x values from the difference curve where the local maxima are located.\n",
        "    :vartype x_difference_maxima: numpy array\n",
        "    :ivar y_difference_maxima: The y values from the difference curve where the local maxima are located.\n",
        "    :vartype y_difference_maxima: numpy array\n",
        "    :ivar minima_indices: The indices of each of the minima on the difference curve.\n",
        "    :vartype minima_indices: numpy array\n",
        "    :ivar minima_indices: The indices of each of the minima on the difference curve.\n",
        "    :vartype maxima_indices: numpy array\n",
        "    :ivar x_difference_minima: The x values from the difference curve where the local minima are located.\n",
        "    :vartype x_difference_minima: numpy array\n",
        "    :ivar y_difference_minima: The y values from the difference curve where the local minima are located.\n",
        "    :vartype y_difference_minima: numpy array\n",
        "    :ivar Tmx: The y values that correspond to the thresholds on the difference curve for determining the knee point.\n",
        "    :vartype Tmx: numpy array\n",
        "    :ivar knee: The x value of the knee point. None if no knee/elbow was detected.\n",
        "    :vartype knee: float\n",
        "    :ivar knee_y: The y value of the knee point. None if no knee/elbow was detected\n",
        "    :vartype knee_y: float\n",
        "    :ivar norm_knee: The normalized x value of the knee point. None if no knee/elbow was detected\n",
        "    :vartype norm_knee: float\n",
        "    :ivar norm_knee_y: The normalized y value of the knee point. None if no knee/elbow was detected\n",
        "    :vartype norm_knee_y: float\n",
        "    :ivar all_knees: The x values of all the identified knee points.\n",
        "    :vartype all_knees: set\n",
        "    :ivar all_knees_y: The y values of all the identified knee points.\n",
        "    :vartype all_knees: set\n",
        "    :ivar all_norm_knees: The normalized x values of all the identified knee points.\n",
        "    :vartype all_norm_knees: set\n",
        "    :ivar all_norm_knees_y: The normalized y values of all the identified knee points.\n",
        "    :vartype all_norm_knees: set\n",
        "    :ivar elbow: The x value of the elbow point (elbow and knee are interchangeable). None if no knee/elbow was detected\n",
        "    :vartype elbow: float\n",
        "    :ivar elbow_y: The y value of the knee point (elbow and knee are interchangeable). None if no knee/elbow was detected\n",
        "    :vartype elbow_y: float\n",
        "    :ivar norm_elbow: The normalized x value of the knee point (elbow and knee are interchangeable). None if no knee/elbow was detected\n",
        "    :vartype norm_knee: float\n",
        "    :ivar norm_elbow_y: The normalized y value of the knee point (elbow and knee are interchangeable). None if no knee/elbow was detected\n",
        "    :vartype norm_elbow_y: float\n",
        "    :ivar all_elbows: The x values of all the identified knee points (elbow and knee are interchangeable).\n",
        "    :vartype all_elbows: set\n",
        "    :ivar all_elbows_y: The y values of all the identified knee points (elbow and knee are interchangeable).\n",
        "    :vartype all_elbows: set\n",
        "    :ivar all_norm_elbows: The normalized x values of all the identified knee points (elbow and knee are interchangeable).\n",
        "    :vartype all_norm_elbows: set\n",
        "    :ivar all_norm_elbows_y: The normalized y values of all the identified knee points (elbow and knee are interchangeable).\n",
        "    :vartype all_norm_elbows: set\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        x: Iterable[float],\n",
        "        y: Iterable[float],\n",
        "        S: float = 1.0,\n",
        "        curve: str = \"concave\",\n",
        "        direction: str = \"increasing\",\n",
        "        interp_method: str = \"interp1d\",\n",
        "        online: bool = False,\n",
        "        polynomial_degree: int = 7,\n",
        "    ):\n",
        "        # Step 0: Raw Input\n",
        "        self.x = np.array(x)\n",
        "        self.y = np.array(y)\n",
        "        self.curve = curve\n",
        "        self.direction = direction\n",
        "        self.N = len(self.x)\n",
        "        self.S = S\n",
        "        self.all_knees = set()\n",
        "        self.all_norm_knees = set()\n",
        "        self.all_knees_y = []\n",
        "        self.all_norm_knees_y = []\n",
        "        self.online = online\n",
        "        self.polynomial_degree = polynomial_degree\n",
        "\n",
        "        # I'm implementing Look Before You Leap (LBYL) validation for direction\n",
        "        # and curve arguments. This is not preferred in Python. The motivation\n",
        "        # is that the logic inside the conditional once y_difference[j] is less\n",
        "        # than threshold in find_knee() could have been evaluated improperly if\n",
        "        # they weren't one of convex, concave, increasing, or decreasing,\n",
        "        # respectively.\n",
        "        valid_curve = self.curve in VALID_CURVE\n",
        "        valid_direction = self.direction in VALID_DIRECTION\n",
        "        if not all((valid_curve, valid_direction)):\n",
        "            raise ValueError(\n",
        "                \"Please check that the curve and direction arguments are valid.\"\n",
        "            )\n",
        "\n",
        "        # Step 1: fit a smooth line\n",
        "        if interp_method == \"interp1d\":\n",
        "            uspline = interpolate.interp1d(self.x, self.y)\n",
        "            self.Ds_y = uspline(self.x)\n",
        "        elif interp_method == \"polynomial\":\n",
        "            p = np.poly1d(np.polyfit(x, y, self.polynomial_degree))\n",
        "            self.Ds_y = p(x)\n",
        "        else:\n",
        "            raise ValueError(\n",
        "                \"{} is an invalid interp_method parameter, use either 'interp1d' or 'polynomial'\".format(\n",
        "                    interp_method\n",
        "                )\n",
        "            )\n",
        "\n",
        "        # Step 2: normalize values\n",
        "        self.x_normalized = self.__normalize(self.x)\n",
        "        self.y_normalized = self.__normalize(self.Ds_y)\n",
        "\n",
        "        # Step 3: Calculate the Difference curve\n",
        "        self.y_normalized = self.transform_y(\n",
        "            self.y_normalized, self.direction, self.curve\n",
        "        )\n",
        "        # normalized difference curve\n",
        "        self.y_difference = self.y_normalized - self.x_normalized\n",
        "        self.x_difference = self.x_normalized.copy()\n",
        "\n",
        "        # Step 4: Identify local maxima/minima\n",
        "        # local maxima\n",
        "        self.maxima_indices = argrelextrema(self.y_difference, np.greater_equal)[0]\n",
        "        self.x_difference_maxima = self.x_difference[self.maxima_indices]\n",
        "        self.y_difference_maxima = self.y_difference[self.maxima_indices]\n",
        "\n",
        "        # local minima\n",
        "        self.minima_indices = argrelextrema(self.y_difference, np.less_equal)[0]\n",
        "        self.x_difference_minima = self.x_difference[self.minima_indices]\n",
        "        self.y_difference_minima = self.y_difference[self.minima_indices]\n",
        "\n",
        "        # Step 5: Calculate thresholds\n",
        "        self.Tmx = self.y_difference_maxima - (\n",
        "            self.S * np.abs(np.diff(self.x_normalized).mean())\n",
        "        )\n",
        "\n",
        "        # Step 6: find knee\n",
        "        self.knee, self.norm_knee = self.find_knee()\n",
        "\n",
        "        # Step 7: If we have a knee, extract data about it\n",
        "        self.knee_y = self.norm_knee_y = None\n",
        "        if self.knee:\n",
        "            self.knee_y = self.y[self.x == self.knee][0]\n",
        "            self.norm_knee_y = self.y_normalized[self.x_normalized == self.norm_knee][0]\n",
        "\n",
        "    @staticmethod\n",
        "    def __normalize(a: Iterable[float]) -> Iterable[float]:\n",
        "        \"\"\"normalize an array\n",
        "        :param a: The array to normalize\n",
        "        \"\"\"\n",
        "        return (a - min(a)) / (max(a) - min(a))\n",
        "\n",
        "    @staticmethod\n",
        "    def transform_y(y: Iterable[float], direction: str, curve: str) -> float:\n",
        "        \"\"\"transform y to concave, increasing based on given direction and curve\"\"\"\n",
        "        # convert elbows to knees\n",
        "        if direction == \"decreasing\":\n",
        "            if curve == \"concave\":\n",
        "                y = np.flip(y)\n",
        "            elif curve == \"convex\":\n",
        "                y = y.max() - y\n",
        "        elif direction == \"increasing\" and curve == \"convex\":\n",
        "            y = np.flip(y.max() - y)\n",
        "\n",
        "        return y\n",
        "\n",
        "    def find_knee(\n",
        "        self,\n",
        "    ):\n",
        "        \"\"\"This function is called when KneeLocator is instantiated. It identifies the knee value and sets the instance attributes.\"\"\"\n",
        "        if not self.maxima_indices.size:\n",
        "            # No local maxima found in the difference curve\n",
        "            # The line is probably not polynomial, try plotting\n",
        "            # the difference curve with plt.plot(knee.x_difference, knee.y_difference)\n",
        "            # Also check that you aren't mistakenly setting the curve argument\n",
        "            return None, None\n",
        "        # placeholder for which threshold region i is located in.\n",
        "        maxima_threshold_index = 0\n",
        "        minima_threshold_index = 0\n",
        "        traversed_maxima = False\n",
        "        # traverse the difference curve\n",
        "        for i, x in enumerate(self.x_difference):\n",
        "            # skip points on the curve before the the first local maxima\n",
        "            if i < self.maxima_indices[0]:\n",
        "                continue\n",
        "\n",
        "            j = i + 1\n",
        "\n",
        "            # reached the end of the curve\n",
        "            if i == (len(self.x_difference) - 1):\n",
        "                break\n",
        "\n",
        "            # if we're at a local max, increment the maxima threshold index and continue\n",
        "            if (self.maxima_indices == i).any():\n",
        "                threshold = self.Tmx[maxima_threshold_index]\n",
        "                threshold_index = i\n",
        "                maxima_threshold_index += 1\n",
        "            # values in difference curve are at or after a local minimum\n",
        "            if (self.minima_indices == i).any():\n",
        "                threshold = 0.0\n",
        "                minima_threshold_index += 1\n",
        "\n",
        "            if self.y_difference[j] < threshold:\n",
        "                if self.curve == \"convex\":\n",
        "                    if self.direction == \"decreasing\":\n",
        "                        knee = self.x[threshold_index]\n",
        "                        norm_knee = self.x_normalized[threshold_index]\n",
        "                    else:\n",
        "                        knee = self.x[-(threshold_index + 1)]\n",
        "                        norm_knee = self.x_normalized[threshold_index]\n",
        "\n",
        "                elif self.curve == \"concave\":\n",
        "                    if self.direction == \"decreasing\":\n",
        "                        knee = self.x[-(threshold_index + 1)]\n",
        "                        norm_knee = self.x_normalized[threshold_index]\n",
        "                    else:\n",
        "                        knee = self.x[threshold_index]\n",
        "                        norm_knee = self.x_normalized[threshold_index]\n",
        "\n",
        "                # add the y value at the knee\n",
        "                y_at_knee = self.y[self.x == knee][0]\n",
        "                y_norm_at_knee = self.y_normalized[self.x_normalized == norm_knee][0]\n",
        "                if knee not in self.all_knees:\n",
        "                    self.all_knees_y.append(y_at_knee)\n",
        "                    self.all_norm_knees_y.append(y_norm_at_knee)\n",
        "\n",
        "                # now add the knee\n",
        "                self.all_knees.add(knee)\n",
        "                self.all_norm_knees.add(norm_knee)\n",
        "\n",
        "                # if detecting in offline mode, return the first knee found\n",
        "                if self.online is False:\n",
        "                    return knee, norm_knee\n",
        "\n",
        "        if self.all_knees == set():\n",
        "            # No knee was found\n",
        "            return None, None\n",
        "\n",
        "        return knee, norm_knee\n",
        "\n",
        "    def plot_knee_normalized(\n",
        "        self,\n",
        "        figsize: Optional[Tuple[int, int]] = None,\n",
        "        title: str = \"Normalized Knee Point\",\n",
        "        xlabel: Optional[str] = None,\n",
        "        ylabel: Optional[str] = None,\n",
        "    ):\n",
        "        \"\"\"Plot the normalized curve, the difference curve (x_difference, y_normalized) and the knee, if it exists.\n",
        "\n",
        "        :param figsize: Optional[Tuple[int, int]\n",
        "            The figure size of the plot. Example (12, 8)\n",
        "        :param title: str\n",
        "            Title of the visualization, defaults to \"Normalized Knee Point\"\n",
        "        :param xlabel: Optional[str]\n",
        "            X-axis label\n",
        "        :param ylabel: Optional[str]\n",
        "            y-axis label\n",
        "        :return: NoReturn\n",
        "        \"\"\"\n",
        "        if not _has_matplotlib:\n",
        "            raise _matplotlib_not_found_err\n",
        "\n",
        "        if figsize is None:\n",
        "            figsize = (6, 6)\n",
        "\n",
        "        plt.figure(figsize=figsize)\n",
        "        plt.title(title)\n",
        "        if xlabel:\n",
        "            plt.xlabel(xlabel)\n",
        "        if ylabel:\n",
        "            plt.ylabel(ylabel)\n",
        "        plt.plot(self.x_normalized, self.y_normalized, \"b\", label=\"normalized curve\")\n",
        "        plt.plot(self.x_difference, self.y_difference, \"r\", label=\"difference curve\")\n",
        "        plt.xticks(\n",
        "            np.arange(self.x_normalized.min(), self.x_normalized.max() + 0.1, 0.1)\n",
        "        )\n",
        "        plt.yticks(\n",
        "            np.arange(self.y_difference.min(), self.y_normalized.max() + 0.1, 0.1)\n",
        "        )\n",
        "\n",
        "        plt.vlines(\n",
        "            self.norm_knee,\n",
        "            plt.ylim()[0],\n",
        "            plt.ylim()[1],\n",
        "            linestyles=\"--\",\n",
        "            label=\"knee/elbow\",\n",
        "        )\n",
        "        plt.legend(loc=\"best\")\n",
        "\n",
        "    def plot_knee(\n",
        "        self,\n",
        "        figsize: Optional[Tuple[int, int]] = None,\n",
        "        title: str = \"Knee Point\",\n",
        "        xlabel: Optional[str] = None,\n",
        "        ylabel: Optional[str] = None,\n",
        "    ):\n",
        "        \"\"\"\n",
        "        Plot the curve and the knee, if it exists\n",
        "\n",
        "        :param figsize: Optional[Tuple[int, int]\n",
        "            The figure size of the plot. Example (12, 8)\n",
        "        :param title: str\n",
        "            Title of the visualization, defaults to \"Knee Point\"\n",
        "        :param xlabel: Optional[str]\n",
        "            X-axis label\n",
        "        :param ylabel: Optional[str]\n",
        "            y-axis label\n",
        "        :return: NoReturn\n",
        "        \"\"\"\n",
        "        if not _has_matplotlib:\n",
        "            raise _matplotlib_not_found_err\n",
        "\n",
        "        if figsize is None:\n",
        "            figsize = (6, 6)\n",
        "\n",
        "        plt.figure(figsize=figsize)\n",
        "        plt.title(title)\n",
        "        if xlabel:\n",
        "            plt.xlabel(xlabel)\n",
        "        if ylabel:\n",
        "            plt.ylabel(ylabel)\n",
        "        plt.plot(self.x, self.y, \"b\", label=\"data\")\n",
        "        plt.vlines(\n",
        "            self.knee, plt.ylim()[0], plt.ylim()[1], linestyles=\"--\", label=\"knee/elbow\"\n",
        "        )\n",
        "        plt.legend(loc=\"best\")\n",
        "\n",
        "    # Niceties for users working with elbows rather than knees\n",
        "    @property\n",
        "    def elbow(self):\n",
        "        return self.knee\n",
        "\n",
        "    @property\n",
        "    def norm_elbow(self):\n",
        "        return self.norm_knee\n",
        "\n",
        "    @property\n",
        "    def elbow_y(self):\n",
        "        return self.knee_y\n",
        "\n",
        "    @property\n",
        "    def norm_elbow_y(self):\n",
        "        return self.norm_knee_y\n",
        "\n",
        "    @property\n",
        "    def all_elbows(self):\n",
        "        return self.all_knees\n",
        "\n",
        "    @property\n",
        "    def all_norm_elbows(self):\n",
        "        return self.all_norm_knees\n",
        "\n",
        "    @property\n",
        "    def all_elbows_y(self):\n",
        "        return self.all_knees_y\n",
        "\n",
        "    @property\n",
        "    def all_norm_elbows_y(self):\n",
        "        return self.all_norm_knees_y"
      ],
      "metadata": {
        "id": "o9rE14Ub0vkp"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_case_images = []\n",
        "\n",
        "# Read the dataframe of the original images from a CSV file\n",
        "df = pd.read_csv(path_to_images + 'image_index_with_gps_and_clusters.csv')\n",
        "df['file_path'].apply(lambda fp: test_case_images.append(fp))\n",
        "\n",
        "# Run the YOLOv8 model and get a YOLO Results object for\n",
        "# each file named in the df\n",
        "# https://docs.ultralytics.com/modes/predict/#working-with-results\n",
        "for test_case in test_case_images:\n",
        "  results = cat_detector_model.predict(source=os.path.join(path_to_images, test_case))\n",
        "  # Extract the image sub areas and save them as files\n",
        "  for r in results:\n",
        "    r.save_crop(save_dir=path_to_cropped_images)\n",
        "\n",
        "path_to_cropped_and_classified_images = os.path.join(path_to_cropped_images, 'cat')\n",
        "# Compile a list of all the cropped images\n",
        "cropped_image_files = []\n",
        "with os.scandir(path_to_cropped_and_classified_images) as files:\n",
        "  for file in files:\n",
        "    cropped_image_files.append(file.name)\n",
        "\n",
        "# Extract the features from each test case image\n",
        "data = {}\n",
        "for cropped_image_file in cropped_image_files:\n",
        "  feature = extract_features(os.path.join(path_to_cropped_and_classified_images, cropped_image_file), image_cluster_model)\n",
        "  data[cropped_image_file] = feature\n",
        "\n",
        "# Get list of filenames\n",
        "filenames = np.array(list(data.keys()))\n",
        "# Get a list of just the features\n",
        "feat = np.array(list(data.values()))\n",
        "feat = feat.reshape(-1,4096)\n",
        "\n",
        "x_values = []\n",
        "y_values = []\n",
        "\n",
        "pca = PCA(n_components = 100, random_state=22)\n",
        "pca.fit(feat)\n",
        "\n",
        "for i in range(len(filenames)):\n",
        "  kmeans = KMeans(n_clusters=i+1, n_init='auto', random_state=22)\n",
        "  x = pca.transform(feat)\n",
        "  kmeans.fit(x)\n",
        "  x = x_values.append(i+1)\n",
        "  y = y_values.append(kmeans.inertia_)\n",
        "plt.plot(x_values, y_values)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "KdYIFUKHz71q",
        "outputId": "40f38d7c-7844-4439-9364-bcf959e4facd"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "image 1/1 /content/gdrive/My Drive/Cat images/original_images/nreading/Places - 1 of 5.jpeg: 480x640 2 cats, 7.4ms\n",
            "Speed: 4.1ms preprocess, 7.4ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "image 1/1 /content/gdrive/My Drive/Cat images/original_images/nreading/Places - 2 of 5.jpeg: 480x640 2 cats, 6.8ms\n",
            "Speed: 4.3ms preprocess, 6.8ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "image 1/1 /content/gdrive/My Drive/Cat images/original_images/nreading/Places - 3 of 5.jpeg: 480x640 1 cat, 7.3ms\n",
            "Speed: 3.0ms preprocess, 7.3ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "image 1/1 /content/gdrive/My Drive/Cat images/original_images/nreading/Places - 4 of 5.jpeg: 480x640 3 cats, 9.7ms\n",
            "Speed: 3.2ms preprocess, 9.7ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "image 1/1 /content/gdrive/My Drive/Cat images/original_images/nreading/Places - 5 of 5.jpeg: 480x640 2 cats, 11.4ms\n",
            "Speed: 5.0ms preprocess, 11.4ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "image 1/1 /content/gdrive/My Drive/Cat images/original_images/nreading/Chuff 2014-04 - 1 of 8.jpeg: 480x640 2 cats, 6.6ms\n",
            "Speed: 3.0ms preprocess, 6.6ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "image 1/1 /content/gdrive/My Drive/Cat images/original_images/nreading/Chuff 2014-04 - 2 of 8.jpeg: 480x640 1 cat, 6.5ms\n",
            "Speed: 3.0ms preprocess, 6.5ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "image 1/1 /content/gdrive/My Drive/Cat images/original_images/nreading/Chuff 2014-04 - 3 of 8.jpeg: 480x640 1 cat, 11.8ms\n",
            "Speed: 4.2ms preprocess, 11.8ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "image 1/1 /content/gdrive/My Drive/Cat images/original_images/nreading/Chuff 2014-04 - 4 of 8.jpeg: 480x640 1 cat, 12.4ms\n",
            "Speed: 4.1ms preprocess, 12.4ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "image 1/1 /content/gdrive/My Drive/Cat images/original_images/nreading/Chuff 2014-04 - 5 of 8.jpeg: 480x640 1 cat, 9.6ms\n",
            "Speed: 4.5ms preprocess, 9.6ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "image 1/1 /content/gdrive/My Drive/Cat images/original_images/nreading/Chuff 2014-04 - 6 of 8.jpeg: 480x640 1 cat, 27.0ms\n",
            "Speed: 4.3ms preprocess, 27.0ms inference, 6.6ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "image 1/1 /content/gdrive/My Drive/Cat images/original_images/nreading/Chuff 2014-04 - 7 of 8.jpeg: 480x640 2 cats, 9.8ms\n",
            "Speed: 3.1ms preprocess, 9.8ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "image 1/1 /content/gdrive/My Drive/Cat images/original_images/nreading/Chuff 2014-04 - 8 of 8.jpeg: 480x640 1 cat, 7.1ms\n",
            "Speed: 3.2ms preprocess, 7.1ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "image 1/1 /content/gdrive/My Drive/Cat images/original_images/nreading/IMG_0516.jpeg: 480x640 2 cats, 6.9ms\n",
            "Speed: 3.2ms preprocess, 6.9ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "image 1/1 /content/gdrive/My Drive/Cat images/original_images/nreading/IMG_0613.jpeg: 480x640 1 cat, 8.1ms\n",
            "Speed: 3.1ms preprocess, 8.1ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "image 1/1 /content/gdrive/My Drive/Cat images/original_images/nreading/IMG_0689.jpeg: 480x640 1 cat, 6.3ms\n",
            "Speed: 2.9ms preprocess, 6.3ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "image 1/1 /content/gdrive/My Drive/Cat images/original_images/nreading/IMG_0690.jpeg: 480x640 1 cat, 6.6ms\n",
            "Speed: 3.8ms preprocess, 6.6ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "image 1/1 /content/gdrive/My Drive/Cat images/original_images/nreading/IMG_0691.jpeg: 480x640 1 cat, 6.6ms\n",
            "Speed: 3.1ms preprocess, 6.6ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "image 1/1 /content/gdrive/My Drive/Cat images/original_images/nreading/IMG_0692.jpeg: 480x640 (no detections), 9.6ms\n",
            "Speed: 3.7ms preprocess, 9.6ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "image 1/1 /content/gdrive/My Drive/Cat images/original_images/nreading/IMG_0693.jpeg: 480x640 (no detections), 6.4ms\n",
            "Speed: 3.2ms preprocess, 6.4ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "image 1/1 /content/gdrive/My Drive/Cat images/original_images/nreading/IMG_0694.jpeg: 480x640 1 cat, 6.8ms\n",
            "Speed: 3.1ms preprocess, 6.8ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "image 1/1 /content/gdrive/My Drive/Cat images/original_images/nreading/IMG_0695.jpeg: 480x640 2 cats, 6.5ms\n",
            "Speed: 2.9ms preprocess, 6.5ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "image 1/1 /content/gdrive/My Drive/Cat images/original_images/nreading/IMG_0696.jpeg: 480x640 2 cats, 6.6ms\n",
            "Speed: 3.2ms preprocess, 6.6ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "image 1/1 /content/gdrive/My Drive/Cat images/original_images/nreading/IMG_0697.jpeg: 480x640 1 cat, 6.3ms\n",
            "Speed: 2.9ms preprocess, 6.3ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "image 1/1 /content/gdrive/My Drive/Cat images/original_images/nreading/IMG_0698.jpeg: 480x640 1 cat, 6.8ms\n",
            "Speed: 3.1ms preprocess, 6.8ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "image 1/1 /content/gdrive/My Drive/Cat images/original_images/nreading/IMG_0699.jpeg: 480x640 1 cat, 6.5ms\n",
            "Speed: 3.1ms preprocess, 6.5ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "image 1/1 /content/gdrive/My Drive/Cat images/original_images/nreading/IMG_0700.jpeg: 480x640 (no detections), 6.5ms\n",
            "Speed: 3.2ms preprocess, 6.5ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "image 1/1 /content/gdrive/My Drive/Cat images/original_images/nreading/IMG_0703.jpeg: 480x640 1 cat, 6.8ms\n",
            "Speed: 3.2ms preprocess, 6.8ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "image 1/1 /content/gdrive/My Drive/Cat images/original_images/nreading/IMG_0704.jpeg: 480x640 2 cats, 6.5ms\n",
            "Speed: 2.9ms preprocess, 6.5ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "image 1/1 /content/gdrive/My Drive/Cat images/original_images/nreading/IMG_0985.jpeg: 640x640 2 cats, 10.6ms\n",
            "Speed: 13.2ms preprocess, 10.6ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "image 1/1 /content/gdrive/My Drive/Cat images/original_images/nreading/IMG_0986.jpeg: 640x640 1 cat, 9.3ms\n",
            "Speed: 5.5ms preprocess, 9.3ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "image 1/1 /content/gdrive/My Drive/Cat images/original_images/nreading/IMG_0987.jpeg: 640x640 2 cats, 10.8ms\n",
            "Speed: 5.8ms preprocess, 10.8ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "image 1/1 /content/gdrive/My Drive/Cat images/original_images/nreading/IMG_0988.jpeg: 640x640 1 cat, 12.3ms\n",
            "Speed: 6.6ms preprocess, 12.3ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "image 1/1 /content/gdrive/My Drive/Cat images/original_images/nreading/IMG_0989.jpeg: 640x640 1 cat, 11.7ms\n",
            "Speed: 4.3ms preprocess, 11.7ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "image 1/1 /content/gdrive/My Drive/Cat images/original_images/nreading/IMG_0990.jpeg: 640x640 2 cats, 7.6ms\n",
            "Speed: 3.4ms preprocess, 7.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "image 1/1 /content/gdrive/My Drive/Cat images/original_images/nreading/IMG_0991.jpeg: 640x640 2 cats, 7.4ms\n",
            "Speed: 3.6ms preprocess, 7.4ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "image 1/1 /content/gdrive/My Drive/Cat images/original_images/nreading/IMG_0992.jpeg: 640x640 1 cat, 7.4ms\n",
            "Speed: 3.5ms preprocess, 7.4ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "image 1/1 /content/gdrive/My Drive/Cat images/original_images/nreading/IMG_0996.jpeg: 640x640 1 cat, 7.7ms\n",
            "Speed: 5.3ms preprocess, 7.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "image 1/1 /content/gdrive/My Drive/Cat images/original_images/nreading/IMG_0997.jpeg: 640x640 1 cat, 7.4ms\n",
            "Speed: 3.6ms preprocess, 7.4ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "image 1/1 /content/gdrive/My Drive/Cat images/original_images/nreading/IMG_0998.jpeg: 640x640 1 cat, 7.4ms\n",
            "Speed: 3.7ms preprocess, 7.4ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "image 1/1 /content/gdrive/My Drive/Cat images/original_images/nreading/IMG_0999.jpeg: 640x640 1 cat, 8.8ms\n",
            "Speed: 3.5ms preprocess, 8.8ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "image 1/1 /content/gdrive/My Drive/Cat images/original_images/nreading/IMG_1001.jpeg: 640x640 1 cat, 7.6ms\n",
            "Speed: 5.1ms preprocess, 7.6ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "image 1/1 /content/gdrive/My Drive/Cat images/original_images/nreading/IMG_1002.jpeg: 640x640 3 cats, 7.4ms\n",
            "Speed: 3.5ms preprocess, 7.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "image 1/1 /content/gdrive/My Drive/Cat images/original_images/nreading/IMG_1003.jpeg: 640x640 1 cat, 7.4ms\n",
            "Speed: 3.8ms preprocess, 7.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "image 1/1 /content/gdrive/My Drive/Cat images/original_images/nreading/IMG_1004.jpeg: 640x640 2 cats, 8.4ms\n",
            "Speed: 5.2ms preprocess, 8.4ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "image 1/1 /content/gdrive/My Drive/Cat images/original_images/nreading/IMG_1005.jpeg: 640x640 3 cats, 10.1ms\n",
            "Speed: 3.6ms preprocess, 10.1ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "image 1/1 /content/gdrive/My Drive/Cat images/original_images/nreading/IMG_1006.jpeg: 640x640 1 cat, 7.4ms\n",
            "Speed: 3.4ms preprocess, 7.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "image 1/1 /content/gdrive/My Drive/Cat images/original_images/nreading/IMG_1007.jpeg: 640x640 1 cat, 7.4ms\n",
            "Speed: 5.1ms preprocess, 7.4ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "image 1/1 /content/gdrive/My Drive/Cat images/original_images/nreading/IMG_1008.jpeg: 640x640 2 cats, 7.4ms\n",
            "Speed: 3.6ms preprocess, 7.4ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "image 1/1 /content/gdrive/My Drive/Cat images/original_images/nreading/IMG_1009.jpeg: 640x640 2 cats, 8.7ms\n",
            "Speed: 5.2ms preprocess, 8.7ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "image 1/1 /content/gdrive/My Drive/Cat images/original_images/nreading/IMG_1010.jpeg: 640x640 1 cat, 13.9ms\n",
            "Speed: 5.3ms preprocess, 13.9ms inference, 4.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "image 1/1 /content/gdrive/My Drive/Cat images/original_images/nreading/IMG_1011.jpeg: 640x640 1 cat, 10.6ms\n",
            "Speed: 5.6ms preprocess, 10.6ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "image 1/1 /content/gdrive/My Drive/Cat images/original_images/nreading/IMG_1012.jpeg: 640x640 1 cat, 12.7ms\n",
            "Speed: 5.1ms preprocess, 12.7ms inference, 2.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "image 1/1 /content/gdrive/My Drive/Cat images/original_images/nreading/IMG_1013.jpeg: 640x640 1 cat, 9.0ms\n",
            "Speed: 5.6ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "image 1/1 /content/gdrive/My Drive/Cat images/original_images/nreading/IMG_1014.jpeg: 640x640 1 cat, 7.4ms\n",
            "Speed: 3.6ms preprocess, 7.4ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "image 1/1 /content/gdrive/My Drive/Cat images/original_images/nreading/IMG_1015.jpeg: 640x640 1 cat, 8.5ms\n",
            "Speed: 4.7ms preprocess, 8.5ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "image 1/1 /content/gdrive/My Drive/Cat images/original_images/nreading/IMG_1016.jpeg: 640x640 1 cat, 7.4ms\n",
            "Speed: 3.8ms preprocess, 7.4ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "image 1/1 /content/gdrive/My Drive/Cat images/original_images/nreading/IMG_1017.jpeg: 640x640 1 cat, 7.4ms\n",
            "Speed: 3.9ms preprocess, 7.4ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "image 1/1 /content/gdrive/My Drive/Cat images/original_images/nreading/IMG_1018.jpeg: 640x640 1 cat, 7.4ms\n",
            "Speed: 3.5ms preprocess, 7.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "image 1/1 /content/gdrive/My Drive/Cat images/original_images/nreading/IMG_1019.jpeg: 640x640 1 cat, 9.2ms\n",
            "Speed: 3.4ms preprocess, 9.2ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "image 1/1 /content/gdrive/My Drive/Cat images/original_images/nreading/IMG_1020.jpeg: 640x640 1 cat, 10.4ms\n",
            "Speed: 4.9ms preprocess, 10.4ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "image 1/1 /content/gdrive/My Drive/Cat images/original_images/nreading/IMG_1021.jpeg: 640x640 2 cats, 7.4ms\n",
            "Speed: 4.0ms preprocess, 7.4ms inference, 3.3ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "image 1/1 /content/gdrive/My Drive/Cat images/original_images/nreading/IMG_1022.jpeg: 640x640 1 cat, 7.4ms\n",
            "Speed: 3.7ms preprocess, 7.4ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "image 1/1 /content/gdrive/My Drive/Cat images/original_images/nreading/IMG_1023.jpeg: 640x640 1 cat, 7.4ms\n",
            "Speed: 3.7ms preprocess, 7.4ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "image 1/1 /content/gdrive/My Drive/Cat images/original_images/nreading/IMG_1024.jpeg: 640x640 1 cat, 7.4ms\n",
            "Speed: 4.1ms preprocess, 7.4ms inference, 3.2ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "image 1/1 /content/gdrive/My Drive/Cat images/original_images/nreading/IMG_1025.jpeg: 640x640 2 cats, 7.4ms\n",
            "Speed: 3.9ms preprocess, 7.4ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "image 1/1 /content/gdrive/My Drive/Cat images/original_images/nreading/IMG_1026.jpeg: 640x640 2 cats, 7.4ms\n",
            "Speed: 3.5ms preprocess, 7.4ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "image 1/1 /content/gdrive/My Drive/Cat images/original_images/nreading/IMG_1027.jpeg: 640x640 2 cats, 9.3ms\n",
            "Speed: 3.7ms preprocess, 9.3ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "image 1/1 /content/gdrive/My Drive/Cat images/original_images/nreading/IMG_1028.jpeg: 640x640 2 cats, 11.0ms\n",
            "Speed: 5.6ms preprocess, 11.0ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "image 1/1 /content/gdrive/My Drive/Cat images/original_images/nreading/IMG_1032.jpeg: 640x640 1 cat, 7.4ms\n",
            "Speed: 3.7ms preprocess, 7.4ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "image 1/1 /content/gdrive/My Drive/Cat images/original_images/nreading/IMG_1033.jpeg: 640x640 1 cat, 7.4ms\n",
            "Speed: 3.5ms preprocess, 7.4ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "image 1/1 /content/gdrive/My Drive/Cat images/original_images/nreading/IMG_1034.jpeg: 640x640 1 cat, 8.3ms\n",
            "Speed: 5.0ms preprocess, 8.3ms inference, 3.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "image 1/1 /content/gdrive/My Drive/Cat images/original_images/nreading/IMG_1035.jpeg: 640x640 1 cat, 7.5ms\n",
            "Speed: 3.6ms preprocess, 7.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "image 1/1 /content/gdrive/My Drive/Cat images/original_images/nreading/IMG_1036.jpeg: 640x640 1 cat, 9.0ms\n",
            "Speed: 5.3ms preprocess, 9.0ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "image 1/1 /content/gdrive/My Drive/Cat images/original_images/nreading/IMG_1037.jpeg: 640x640 1 cat, 7.4ms\n",
            "Speed: 3.7ms preprocess, 7.4ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "image 1/1 /content/gdrive/My Drive/Cat images/original_images/nreading/IMG_1038.jpeg: 640x640 1 cat, 9.2ms\n",
            "Speed: 5.2ms preprocess, 9.2ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "image 1/1 /content/gdrive/My Drive/Cat images/original_images/nreading/IMG_1039.jpeg: 640x640 2 cats, 7.4ms\n",
            "Speed: 3.8ms preprocess, 7.4ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "image 1/1 /content/gdrive/My Drive/Cat images/original_images/nreading/IMG_1040.jpeg: 640x640 1 cat, 7.4ms\n",
            "Speed: 3.8ms preprocess, 7.4ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "image 1/1 /content/gdrive/My Drive/Cat images/original_images/nreading/IMG_1041.jpeg: 640x640 2 cats, 10.6ms\n",
            "Speed: 5.2ms preprocess, 10.6ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "image 1/1 /content/gdrive/My Drive/Cat images/original_images/nreading/IMG_1042.jpeg: 640x640 1 cat, 12.2ms\n",
            "Speed: 5.4ms preprocess, 12.2ms inference, 6.9ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "image 1/1 /content/gdrive/My Drive/Cat images/original_images/nreading/IMG_1043.jpeg: 640x640 1 cat, 7.4ms\n",
            "Speed: 3.7ms preprocess, 7.4ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "image 1/1 /content/gdrive/My Drive/Cat images/original_images/nreading/IMG_1044.jpeg: 640x640 1 cat, 7.4ms\n",
            "Speed: 3.7ms preprocess, 7.4ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "image 1/1 /content/gdrive/My Drive/Cat images/original_images/nreading/IMG_1045.jpeg: 640x640 1 cat, 7.5ms\n",
            "Speed: 3.6ms preprocess, 7.5ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "image 1/1 /content/gdrive/My Drive/Cat images/original_images/nreading/IMG_1046.jpeg: 640x640 1 cat, 7.4ms\n",
            "Speed: 3.6ms preprocess, 7.4ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "image 1/1 /content/gdrive/My Drive/Cat images/original_images/nreading/IMG_1047.jpeg: 640x640 1 cat, 7.4ms\n",
            "Speed: 3.5ms preprocess, 7.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "image 1/1 /content/gdrive/My Drive/Cat images/original_images/nreading/IMG_1048.jpeg: 640x640 1 cat, 7.4ms\n",
            "Speed: 4.7ms preprocess, 7.4ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "image 1/1 /content/gdrive/My Drive/Cat images/original_images/nreading/IMG_1049.jpeg: 640x640 1 cat, 7.4ms\n",
            "Speed: 3.7ms preprocess, 7.4ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "image 1/1 /content/gdrive/My Drive/Cat images/original_images/nreading/IMG_1050.jpeg: 640x640 1 cat, 7.4ms\n",
            "Speed: 3.6ms preprocess, 7.4ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "image 1/1 /content/gdrive/My Drive/Cat images/original_images/nreading/IMG_1051.jpeg: 640x640 1 cat, 9.1ms\n",
            "Speed: 4.6ms preprocess, 9.1ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "image 1/1 /content/gdrive/My Drive/Cat images/original_images/nreading/IMG_1052.jpeg: 640x640 1 cat, 11.1ms\n",
            "Speed: 6.1ms preprocess, 11.1ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "image 1/1 /content/gdrive/My Drive/Cat images/original_images/nreading/IMG_1368.jpeg: 480x640 2 cats, 7.7ms\n",
            "Speed: 3.1ms preprocess, 7.7ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "image 1/1 /content/gdrive/My Drive/Cat images/original_images/nreading/IMG_1369.jpeg: 480x640 (no detections), 6.5ms\n",
            "Speed: 2.9ms preprocess, 6.5ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "image 1/1 /content/gdrive/My Drive/Cat images/original_images/nreading/IMG_1446.jpeg: 480x640 1 cat, 8.0ms\n",
            "Speed: 3.2ms preprocess, 8.0ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "image 1/1 /content/gdrive/My Drive/Cat images/original_images/nreading/IMG_1447.jpeg: 480x640 1 cat, 6.4ms\n",
            "Speed: 3.1ms preprocess, 6.4ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "image 1/1 /content/gdrive/My Drive/Cat images/original_images/nreading/IMG_1448.jpeg: 480x640 1 cat, 6.3ms\n",
            "Speed: 3.0ms preprocess, 6.3ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "image 1/1 /content/gdrive/My Drive/Cat images/original_images/nreading/IMG_1449.jpeg: 480x640 (no detections), 6.5ms\n",
            "Speed: 2.9ms preprocess, 6.5ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "image 1/1 /content/gdrive/My Drive/Cat images/original_images/nreading/IMG_1450.jpeg: 480x640 1 cat, 6.5ms\n",
            "Speed: 3.1ms preprocess, 6.5ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "image 1/1 /content/gdrive/My Drive/Cat images/original_images/nreading/IMG_1451.jpeg: 480x640 1 cat, 7.0ms\n",
            "Speed: 3.2ms preprocess, 7.0ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "image 1/1 /content/gdrive/My Drive/Cat images/original_images/nreading/IMG_1452.jpeg: 480x640 1 cat, 11.9ms\n",
            "Speed: 4.3ms preprocess, 11.9ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "image 1/1 /content/gdrive/My Drive/Cat images/original_images/nreading/IMG_1453.jpeg: 480x640 2 cats, 6.6ms\n",
            "Speed: 3.1ms preprocess, 6.6ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "image 1/1 /content/gdrive/My Drive/Cat images/original_images/nreading/IMG_1454.jpeg: 480x640 1 cat, 6.6ms\n",
            "Speed: 3.2ms preprocess, 6.6ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "image 1/1 /content/gdrive/My Drive/Cat images/original_images/nreading/IMG_1455.jpeg: 480x640 1 cat, 9.3ms\n",
            "Speed: 3.1ms preprocess, 9.3ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "image 1/1 /content/gdrive/My Drive/Cat images/original_images/nreading/IMG_1558.jpeg: 480x640 1 cat, 33.7ms\n",
            "Speed: 12.7ms preprocess, 33.7ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "image 1/1 /content/gdrive/My Drive/Cat images/original_images/nreading/IMG_1559.jpeg: 480x640 1 cat, 6.6ms\n",
            "Speed: 3.1ms preprocess, 6.6ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "image 1/1 /content/gdrive/My Drive/Cat images/original_images/nreading/IMG_1560.jpeg: 480x640 1 cat, 9.6ms\n",
            "Speed: 4.1ms preprocess, 9.6ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "image 1/1 /content/gdrive/My Drive/Cat images/original_images/nreading/IMG_1561.jpeg: 480x640 2 cats, 6.6ms\n",
            "Speed: 3.1ms preprocess, 6.6ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "image 1/1 /content/gdrive/My Drive/Cat images/original_images/nreading/IMG_1562.jpeg: 480x640 2 cats, 7.1ms\n",
            "Speed: 3.1ms preprocess, 7.1ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "image 1/1 /content/gdrive/My Drive/Cat images/original_images/nreading/IMG_1648.jpeg: 480x640 1 cat, 6.8ms\n",
            "Speed: 3.0ms preprocess, 6.8ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "image 1/1 /content/gdrive/My Drive/Cat images/original_images/nreading/IMG_1649.jpeg: 640x480 (no detections), 12.2ms\n",
            "Speed: 4.3ms preprocess, 12.2ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "image 1/1 /content/gdrive/My Drive/Cat images/original_images/nreading/IMG_1650.jpeg: 640x480 1 cat, 10.1ms\n",
            "Speed: 4.4ms preprocess, 10.1ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "image 1/1 /content/gdrive/My Drive/Cat images/original_images/nreading/IMG_1651.jpeg: 640x480 1 cat, 17.4ms\n",
            "Speed: 4.5ms preprocess, 17.4ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "image 1/1 /content/gdrive/My Drive/Cat images/original_images/nreading/IMG_1652.jpeg: 640x480 1 cat, 10.1ms\n",
            "Speed: 4.3ms preprocess, 10.1ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "image 1/1 /content/gdrive/My Drive/Cat images/original_images/nreading/IMG_1653.jpeg: 640x480 (no detections), 7.1ms\n",
            "Speed: 3.0ms preprocess, 7.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "image 1/1 /content/gdrive/My Drive/Cat images/original_images/shb/IMG_1292.jpeg: 640x640 (no detections), 8.5ms\n",
            "Speed: 3.4ms preprocess, 8.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "image 1/1 /content/gdrive/My Drive/Cat images/original_images/shb/IMG_1293.jpeg: 640x640 1 cat, 7.4ms\n",
            "Speed: 3.5ms preprocess, 7.4ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "\n",
            "image 1/1 /content/gdrive/My Drive/Cat images/original_images/shb/IMG_1302.jpeg: 480x640 2 cats, 7.2ms\n",
            "Speed: 3.2ms preprocess, 7.2ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "image 1/1 /content/gdrive/My Drive/Cat images/original_images/shb/IMG_1303.jpeg: 480x640 (no detections), 6.6ms\n",
            "Speed: 3.1ms preprocess, 6.6ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "image 1/1 /content/gdrive/My Drive/Cat images/original_images/shb/IMG_1331.jpeg: 480x640 (no detections), 6.8ms\n",
            "Speed: 3.1ms preprocess, 6.8ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "image 1/1 /content/gdrive/My Drive/Cat images/original_images/shb/IMG_1332.jpeg: 480x640 1 cat, 7.8ms\n",
            "Speed: 3.5ms preprocess, 7.8ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "image 1/1 /content/gdrive/My Drive/Cat images/original_images/shb/IMG_1333.jpeg: 480x640 1 cat, 7.0ms\n",
            "Speed: 3.0ms preprocess, 7.0ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "image 1/1 /content/gdrive/My Drive/Cat images/original_images/shb/IMG_1334.jpeg: 640x480 1 cat, 7.8ms\n",
            "Speed: 3.1ms preprocess, 7.8ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "image 1/1 /content/gdrive/My Drive/Cat images/original_images/shb/IMG_1378.jpeg: 480x640 1 cat, 8.0ms\n",
            "Speed: 3.2ms preprocess, 8.0ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "image 1/1 /content/gdrive/My Drive/Cat images/original_images/shb/IMG_1379.jpeg: 480x640 1 cat, 6.8ms\n",
            "Speed: 3.1ms preprocess, 6.8ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "image 1/1 /content/gdrive/My Drive/Cat images/original_images/shb/IMG_1709.jpeg: 480x640 (no detections), 8.7ms\n",
            "Speed: 4.2ms preprocess, 8.7ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "image 1/1 /content/gdrive/My Drive/Cat images/original_images/shb/IMG_1710.jpeg: 480x640 (no detections), 8.7ms\n",
            "Speed: 3.2ms preprocess, 8.7ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "image 1/1 /content/gdrive/My Drive/Cat images/original_images/shb/IMG_1711.jpeg: 480x640 (no detections), 10.3ms\n",
            "Speed: 4.0ms preprocess, 10.3ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "image 1/1 /content/gdrive/My Drive/Cat images/original_images/shb/IMG_1712.jpeg: 480x640 2 cats, 6.9ms\n",
            "Speed: 3.3ms preprocess, 6.9ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "image 1/1 /content/gdrive/My Drive/Cat images/original_images/shb/IMG_1713.jpeg: 480x640 (no detections), 7.8ms\n",
            "Speed: 4.1ms preprocess, 7.8ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "image 1/1 /content/gdrive/My Drive/Cat images/original_images/shb/IMG_1714.jpeg: 480x640 (no detections), 7.2ms\n",
            "Speed: 4.3ms preprocess, 7.2ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "image 1/1 /content/gdrive/My Drive/Cat images/original_images/shb/IMG_1715.jpeg: 480x640 (no detections), 7.1ms\n",
            "Speed: 3.2ms preprocess, 7.1ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "image 1/1 /content/gdrive/My Drive/Cat images/original_images/shb/IMG_1716.jpeg: 480x640 2 cats, 6.7ms\n",
            "Speed: 3.2ms preprocess, 6.7ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "image 1/1 /content/gdrive/My Drive/Cat images/original_images/shb/IMG_1717.jpeg: 480x640 1 cat, 6.8ms\n",
            "Speed: 3.3ms preprocess, 6.8ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "image 1/1 /content/gdrive/My Drive/Cat images/original_images/shb/IMG_1718.jpeg: 480x640 (no detections), 6.7ms\n",
            "Speed: 3.2ms preprocess, 6.7ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "image 1/1 /content/gdrive/My Drive/Cat images/original_images/shb/IMG_1719.jpeg: 480x640 2 cats, 8.3ms\n",
            "Speed: 4.1ms preprocess, 8.3ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "image 1/1 /content/gdrive/My Drive/Cat images/original_images/shb/IMG_1720.jpeg: 480x640 (no detections), 8.6ms\n",
            "Speed: 4.6ms preprocess, 8.6ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "image 1/1 /content/gdrive/My Drive/Cat images/original_images/shb/IMG_1721.jpeg: 480x640 1 cat, 9.5ms\n",
            "Speed: 4.4ms preprocess, 9.5ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "image 1/1 /content/gdrive/My Drive/Cat images/original_images/shb/IMG_1722.jpeg: 640x480 (no detections), 10.8ms\n",
            "Speed: 4.3ms preprocess, 10.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "image 1/1 /content/gdrive/My Drive/Cat images/original_images/shb/IMG_1723.jpeg: 640x480 (no detections), 8.3ms\n",
            "Speed: 3.3ms preprocess, 8.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "image 1/1 /content/gdrive/My Drive/Cat images/original_images/shb/IMG_1724.jpeg: 640x480 (no detections), 6.9ms\n",
            "Speed: 4.0ms preprocess, 6.9ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "image 1/1 /content/gdrive/My Drive/Cat images/original_images/shb/IMG_1725.jpeg: 640x480 (no detections), 8.7ms\n",
            "Speed: 3.3ms preprocess, 8.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "image 1/1 /content/gdrive/My Drive/Cat images/original_images/shb/IMG_1726.jpeg: 640x480 (no detections), 6.8ms\n",
            "Speed: 3.2ms preprocess, 6.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "image 1/1 /content/gdrive/My Drive/Cat images/original_images/shb/IMG_1727.jpeg: 640x480 2 cats, 8.1ms\n",
            "Speed: 4.4ms preprocess, 8.1ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "image 1/1 /content/gdrive/My Drive/Cat images/original_images/shb/IMG_1728.jpeg: 640x480 (no detections), 6.8ms\n",
            "Speed: 3.8ms preprocess, 6.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "image 1/1 /content/gdrive/My Drive/Cat images/original_images/shb/IMG_1729.jpeg: 640x480 (no detections), 9.8ms\n",
            "Speed: 4.5ms preprocess, 9.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "image 1/1 /content/gdrive/My Drive/Cat images/original_images/shb/IMG_1730.jpeg: 640x480 1 cat, 7.9ms\n",
            "Speed: 3.4ms preprocess, 7.9ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "image 1/1 /content/gdrive/My Drive/Cat images/original_images/shb/IMG_1731.jpeg: 640x480 (no detections), 11.9ms\n",
            "Speed: 3.1ms preprocess, 11.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "image 1/1 /content/gdrive/My Drive/Cat images/original_images/shb/IMG_1732.jpeg: 640x480 (no detections), 6.7ms\n",
            "Speed: 3.2ms preprocess, 6.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "image 1/1 /content/gdrive/My Drive/Cat images/original_images/shb/IMG_3786.jpeg: 480x640 2 cats, 7.5ms\n",
            "Speed: 3.3ms preprocess, 7.5ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "image 1/1 /content/gdrive/My Drive/Cat images/original_images/shb/IMG_3787.jpeg: 480x640 1 cat, 6.6ms\n",
            "Speed: 3.1ms preprocess, 6.6ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "image 1/1 /content/gdrive/My Drive/Cat images/original_images/shb/IMG_3804.jpeg: 480x640 2 cats, 6.3ms\n",
            "Speed: 3.2ms preprocess, 6.3ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "image 1/1 /content/gdrive/My Drive/Cat images/original_images/shb/IMG_3882.jpeg: 480x640 1 cat, 6.8ms\n",
            "Speed: 3.1ms preprocess, 6.8ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "image 1/1 /content/gdrive/My Drive/Cat images/original_images/shb/IMG_3884.jpeg: 480x640 2 cats, 10.0ms\n",
            "Speed: 11.8ms preprocess, 10.0ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "image 1/1 /content/gdrive/My Drive/Cat images/original_images/shb/IMG_3921.jpeg: 640x480 2 cats, 9.4ms\n",
            "Speed: 4.2ms preprocess, 9.4ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "image 1/1 /content/gdrive/My Drive/Cat images/original_images/shb/IMG_3925.jpeg: 480x640 1 cat, 12.6ms\n",
            "Speed: 4.2ms preprocess, 12.6ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "image 1/1 /content/gdrive/My Drive/Cat images/original_images/shb/IMG_3926.jpeg: 640x480 1 cat, 7.0ms\n",
            "Speed: 3.2ms preprocess, 7.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "image 1/1 /content/gdrive/My Drive/Cat images/original_images/shb/IMG_3927.jpeg: 480x640 1 cat, 7.1ms\n",
            "Speed: 3.3ms preprocess, 7.1ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "image 1/1 /content/gdrive/My Drive/Cat images/original_images/shb/IMG_3928.jpeg: 480x640 1 cat, 7.5ms\n",
            "Speed: 4.3ms preprocess, 7.5ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "image 1/1 /content/gdrive/My Drive/Cat images/original_images/shb/IMG_3929.jpeg: 480x640 2 cats, 7.2ms\n",
            "Speed: 3.2ms preprocess, 7.2ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "image 1/1 /content/gdrive/My Drive/Cat images/original_images/shb/IMG_3930.jpeg: 640x480 1 cat, 7.2ms\n",
            "Speed: 3.7ms preprocess, 7.2ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "image 1/1 /content/gdrive/My Drive/Cat images/original_images/shb/IMG_3931.jpeg: 640x480 1 cat, 7.3ms\n",
            "Speed: 4.3ms preprocess, 7.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "image 1/1 /content/gdrive/My Drive/Cat images/original_images/shb/IMG_3932.jpeg: 640x480 1 cat, 6.7ms\n",
            "Speed: 3.7ms preprocess, 6.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "image 1/1 /content/gdrive/My Drive/Cat images/original_images/shb/IMG_3933.jpeg: 640x480 2 cats, 6.7ms\n",
            "Speed: 3.1ms preprocess, 6.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "image 1/1 /content/gdrive/My Drive/Cat images/original_images/shb/IMG_3935.jpeg: 480x640 1 cat, 7.8ms\n",
            "Speed: 3.6ms preprocess, 7.8ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "image 1/1 /content/gdrive/My Drive/Cat images/original_images/shb/IMG_3936.jpeg: 640x480 3 cats, 15.1ms\n",
            "Speed: 4.7ms preprocess, 15.1ms inference, 2.3ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "image 1/1 /content/gdrive/My Drive/Cat images/original_images/shb/IMG_3988.jpeg: 480x640 (no detections), 10.3ms\n",
            "Speed: 4.3ms preprocess, 10.3ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "image 1/1 /content/gdrive/My Drive/Cat images/original_images/shb/IMG_4006.jpeg: 640x480 2 cats, 10.0ms\n",
            "Speed: 4.6ms preprocess, 10.0ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "image 1/1 /content/gdrive/My Drive/Cat images/original_images/shb/IMG_4020.jpeg: 640x480 1 cat, 8.6ms\n",
            "Speed: 3.2ms preprocess, 8.6ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "image 1/1 /content/gdrive/My Drive/Cat images/original_images/shb/IMG_4021.jpeg: 640x480 1 cat, 11.5ms\n",
            "Speed: 13.7ms preprocess, 11.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "image 1/1 /content/gdrive/My Drive/Cat images/original_images/shb/IMG_4024.jpeg: 640x480 1 cat, 6.5ms\n",
            "Speed: 3.2ms preprocess, 6.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "image 1/1 /content/gdrive/My Drive/Cat images/original_images/shb/IMG_4026.jpeg: 640x480 1 cat, 6.6ms\n",
            "Speed: 3.1ms preprocess, 6.6ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "image 1/1 /content/gdrive/My Drive/Cat images/original_images/shb/IMG_4027.jpeg: 640x480 2 cats, 6.4ms\n",
            "Speed: 3.7ms preprocess, 6.4ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "image 1/1 /content/gdrive/My Drive/Cat images/original_images/shb/IMG_4045.jpeg: 480x640 (no detections), 9.1ms\n",
            "Speed: 3.0ms preprocess, 9.1ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "image 1/1 /content/gdrive/My Drive/Cat images/original_images/shb/IMG_4047.jpeg: 480x640 2 cats, 9.4ms\n",
            "Speed: 4.1ms preprocess, 9.4ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "image 1/1 /content/gdrive/My Drive/Cat images/original_images/shb/IMG_4048.jpeg: 640x480 1 cat, 7.3ms\n",
            "Speed: 3.8ms preprocess, 7.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "image 1/1 /content/gdrive/My Drive/Cat images/original_images/shb/IMG_4049.jpeg: 640x480 1 cat, 6.5ms\n",
            "Speed: 3.1ms preprocess, 6.5ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "image 1/1 /content/gdrive/My Drive/Cat images/original_images/shb/IMG_4050.jpeg: 640x480 2 cats, 6.4ms\n",
            "Speed: 3.2ms preprocess, 6.4ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "image 1/1 /content/gdrive/My Drive/Cat images/original_images/shb/IMG_4051.jpeg: 640x480 2 cats, 7.0ms\n",
            "Speed: 3.6ms preprocess, 7.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "image 1/1 /content/gdrive/My Drive/Cat images/original_images/shb/IMG_4054.jpeg: 480x640 2 cats, 11.5ms\n",
            "Speed: 5.0ms preprocess, 11.5ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "image 1/1 /content/gdrive/My Drive/Cat images/original_images/shb/IMG_4055.jpeg: 640x480 1 cat, 7.9ms\n",
            "Speed: 6.0ms preprocess, 7.9ms inference, 1.6ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "image 1/1 /content/gdrive/My Drive/Cat images/original_images/shb/IMG_4065.jpeg: 480x640 1 cat, 10.1ms\n",
            "Speed: 4.5ms preprocess, 10.1ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "image 1/1 /content/gdrive/My Drive/Cat images/original_images/shb/IMG_4066.jpeg: 480x640 1 cat, 9.3ms\n",
            "Speed: 4.3ms preprocess, 9.3ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "image 1/1 /content/gdrive/My Drive/Cat images/original_images/shb/IMG_4071.jpeg: 480x640 2 cats, 9.2ms\n",
            "Speed: 4.4ms preprocess, 9.2ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "image 1/1 /content/gdrive/My Drive/Cat images/original_images/shb/IMG_4072.jpeg: 480x640 1 cat, 6.7ms\n",
            "Speed: 3.2ms preprocess, 6.7ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "image 1/1 /content/gdrive/My Drive/Cat images/original_images/shb/IMG_4216.jpeg: 480x640 1 cat, 8.9ms\n",
            "Speed: 4.1ms preprocess, 8.9ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "image 1/1 /content/gdrive/My Drive/Cat images/original_images/shb/IMG_4217.jpeg: 480x640 1 cat, 8.7ms\n",
            "Speed: 4.3ms preprocess, 8.7ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "image 1/1 /content/gdrive/My Drive/Cat images/original_images/shb/IMG_4330.jpeg: 480x640 1 cat, 10.9ms\n",
            "Speed: 4.4ms preprocess, 10.9ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "image 1/1 /content/gdrive/My Drive/Cat images/original_images/shb/IMG_4337.jpeg: 480x640 1 cat, 12.1ms\n",
            "Speed: 4.5ms preprocess, 12.1ms inference, 3.3ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "image 1/1 /content/gdrive/My Drive/Cat images/original_images/shb/IMG_4339.jpeg: 480x640 1 cat, 7.7ms\n",
            "Speed: 3.6ms preprocess, 7.7ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "image 1/1 /content/gdrive/My Drive/Cat images/original_images/shb/IMG_4340.jpeg: 480x640 1 cat, 6.4ms\n",
            "Speed: 3.6ms preprocess, 6.4ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "image 1/1 /content/gdrive/My Drive/Cat images/original_images/shb/IMG_4341.jpeg: 480x640 1 cat, 9.2ms\n",
            "Speed: 5.0ms preprocess, 9.2ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "image 1/1 /content/gdrive/My Drive/Cat images/original_images/shb/IMG_4342.jpeg: 480x640 1 cat, 6.8ms\n",
            "Speed: 3.3ms preprocess, 6.8ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "image 1/1 /content/gdrive/My Drive/Cat images/original_images/shb/IMG_4343.jpeg: 480x640 1 cat, 6.6ms\n",
            "Speed: 3.1ms preprocess, 6.6ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "image 1/1 /content/gdrive/My Drive/Cat images/original_images/shb/IMG_4571.jpeg: 640x480 1 cat, 9.0ms\n",
            "Speed: 3.8ms preprocess, 9.0ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "image 1/1 /content/gdrive/My Drive/Cat images/original_images/shb/IMG_4573.jpeg: 640x480 1 cat, 9.7ms\n",
            "Speed: 3.9ms preprocess, 9.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "image 1/1 /content/gdrive/My Drive/Cat images/original_images/shb/IMG_4575.jpeg: 640x480 1 cat, 6.5ms\n",
            "Speed: 3.8ms preprocess, 6.5ms inference, 3.4ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "image 1/1 /content/gdrive/My Drive/Cat images/original_images/shb/IMG_4601.jpeg: 640x480 1 cat, 8.9ms\n",
            "Speed: 3.0ms preprocess, 8.9ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "image 1/1 /content/gdrive/My Drive/Cat images/original_images/shb/IMG_4605.jpeg: 640x480 1 cat, 8.8ms\n",
            "Speed: 4.3ms preprocess, 8.8ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "image 1/1 /content/gdrive/My Drive/Cat images/original_images/shb/IMG_4609.jpeg: 640x480 1 cat, 8.7ms\n",
            "Speed: 4.3ms preprocess, 8.7ms inference, 1.9ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "image 1/1 /content/gdrive/My Drive/Cat images/original_images/shb/IMG_4611.jpeg: 640x480 1 cat, 12.4ms\n",
            "Speed: 4.3ms preprocess, 12.4ms inference, 2.1ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "image 1/1 /content/gdrive/My Drive/Cat images/original_images/shb/IMG_4619.jpeg: 640x480 1 cat, 6.5ms\n",
            "Speed: 3.2ms preprocess, 6.5ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "image 1/1 /content/gdrive/My Drive/Cat images/original_images/shb/IMG_4625.jpeg: 480x640 1 cat, 7.7ms\n",
            "Speed: 3.3ms preprocess, 7.7ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "image 1/1 /content/gdrive/My Drive/Cat images/original_images/shb/IMG_4628.jpeg: 640x480 1 cat, 8.2ms\n",
            "Speed: 3.6ms preprocess, 8.2ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "image 1/1 /content/gdrive/My Drive/Cat images/original_images/shb/IMG_4629.jpeg: 640x480 1 cat, 6.3ms\n",
            "Speed: 3.1ms preprocess, 6.3ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "image 1/1 /content/gdrive/My Drive/Cat images/original_images/shb/IMG_4630.jpeg: 640x480 2 cats, 7.7ms\n",
            "Speed: 5.0ms preprocess, 7.7ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "image 1/1 /content/gdrive/My Drive/Cat images/original_images/shb/IMG_4633.jpeg: 640x480 1 cat, 6.9ms\n",
            "Speed: 3.2ms preprocess, 6.9ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "image 1/1 /content/gdrive/My Drive/Cat images/original_images/shb/IMG_4635.jpeg: 640x480 1 cat, 7.3ms\n",
            "Speed: 3.5ms preprocess, 7.3ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "image 1/1 /content/gdrive/My Drive/Cat images/original_images/shb/IMG_4637.jpeg: 640x480 1 cat, 7.0ms\n",
            "Speed: 3.6ms preprocess, 7.0ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "image 1/1 /content/gdrive/My Drive/Cat images/original_images/shb/IMG_4655.jpeg: 480x640 (no detections), 7.3ms\n",
            "Speed: 3.3ms preprocess, 7.3ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "image 1/1 /content/gdrive/My Drive/Cat images/original_images/shb/IMG_4656.jpeg: 480x640 (no detections), 7.0ms\n",
            "Speed: 3.3ms preprocess, 7.0ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "image 1/1 /content/gdrive/My Drive/Cat images/original_images/shb/IMG_4656.jpeg: 480x640 (no detections), 7.2ms\n",
            "Speed: 5.0ms preprocess, 7.2ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "image 1/1 /content/gdrive/My Drive/Cat images/original_images/shb/IMG_4827.jpeg: 640x480 (no detections), 9.1ms\n",
            "Speed: 3.3ms preprocess, 9.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "image 1/1 /content/gdrive/My Drive/Cat images/original_images/shb/IMG_4861.jpeg: 640x480 1 cat, 6.8ms\n",
            "Speed: 3.1ms preprocess, 6.8ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "image 1/1 /content/gdrive/My Drive/Cat images/original_images/shb/IMG_4901.jpeg: 480x640 1 cat, 9.7ms\n",
            "Speed: 3.9ms preprocess, 9.7ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "image 1/1 /content/gdrive/My Drive/Cat images/original_images/shb/IMG_4902.jpeg: 640x480 1 cat, 10.5ms\n",
            "Speed: 3.1ms preprocess, 10.5ms inference, 3.5ms postprocess per image at shape (1, 3, 640, 480)\n",
            "\n",
            "image 1/1 /content/gdrive/My Drive/Cat images/original_images/shb/IMG_4975.jpeg: 480x640 2 cats, 10.0ms\n",
            "Speed: 4.5ms preprocess, 10.0ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 1s/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 191ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 1s 804ms/step\n",
            "1/1 [==============================] - 1s 810ms/step\n",
            "1/1 [==============================] - 0s 248ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 52ms/step\n",
            "1/1 [==============================] - 0s 87ms/step\n",
            "1/1 [==============================] - 1s 693ms/step\n",
            "1/1 [==============================] - 1s 865ms/step\n",
            "1/1 [==============================] - 0s 241ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 1s 745ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 1s 796ms/step\n",
            "1/1 [==============================] - 0s 310ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 1s 814ms/step\n",
            "1/1 [==============================] - 1s 819ms/step\n",
            "1/1 [==============================] - 0s 232ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 1s 652ms/step\n",
            "1/1 [==============================] - 1s 835ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 179ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 242ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 1s 825ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 250ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 1s 762ms/step\n",
            "1/1 [==============================] - 1s 832ms/step\n",
            "1/1 [==============================] - 0s 280ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 1s 728ms/step\n",
            "1/1 [==============================] - 1s 825ms/step\n",
            "1/1 [==============================] - 1s 821ms/step\n",
            "1/1 [==============================] - 0s 290ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 247ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 248ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 1s 748ms/step\n",
            "1/1 [==============================] - 0s 287ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 294ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 1s 746ms/step\n",
            "1/1 [==============================] - 0s 267ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 180ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 1s 714ms/step\n",
            "1/1 [==============================] - 1s 828ms/step\n",
            "1/1 [==============================] - 0s 276ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 1s 794ms/step\n",
            "1/1 [==============================] - 1s 852ms/step\n",
            "1/1 [==============================] - 0s 276ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 1s 706ms/step\n",
            "1/1 [==============================] - 1s 833ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 123ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 1s 754ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 1s 782ms/step\n",
            "1/1 [==============================] - 0s 251ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 230ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 1s 803ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 1s 765ms/step\n",
            "1/1 [==============================] - 0s 211ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 1s 889ms/step\n",
            "1/1 [==============================] - 1s 816ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 1s 806ms/step\n",
            "1/1 [==============================] - 1s 817ms/step\n",
            "1/1 [==============================] - 0s 290ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7c82c4f8d6f0>]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sensitivity = [1, 2, 4, 8, 16, 32, 64]\n",
        "elbows = []\n",
        "norm_elbows = []\n",
        "for s in sensitivity:\n",
        "  kn = KneeLocator(x_values, y_values, curve='convex', direction='decreasing', S=s)\n",
        "  elbows.append(kn.elbow)\n",
        "elbows"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rMa-Bbmz1UJJ",
        "outputId": "d7c411e0-5e06-47ec-84af-2268aeef7c02"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[53, 79, 79, 79, 79, 79, 79]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    }
  ]
}